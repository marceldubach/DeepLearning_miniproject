# Report

# Part 1

# clean the code
# statistics: mean and std across 10+ runs
# loss curve: training vs testing (over epochs) -> check overfit
# compare structures of networks:
    - baseline: (no weight sharing)
    - siamese : (no auxiliary loss, but weight sharing)
    - auxiliary: (weight sharing and auxiliary loss)
  State the differences in performance, number of parameters, training speed

# if time (and fun to do it) : (std of weights)

# Part 2

# code: clean the code (make it more robust)

# report:
# explain weight initialization
# justify choices of implementation (coarse), explain how the code is used
# name activation functions
# name loss functions
# loss curve
# choice of learning rate (eta)
# if time: implement cross-entropy